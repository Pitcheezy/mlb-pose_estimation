import cv2
import numpy as np
from ultralytics import YOLO
import os

# --- 1. ì‚¬ìš©í•  ëª¨ë¸ ë° ì˜ìƒ ê²½ë¡œ ì„¤ì • ---

# ìŠ¤í¬ë¦½íŠ¸ì˜ ì ˆëŒ€ ê²½ë¡œë¥¼ ê¸°ì¤€ìœ¼ë¡œ í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ê³„ì‚°
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(os.path.dirname(SCRIPT_DIR))

# â˜…â˜…â˜… ìˆ˜ì • í¬ì¸íŠ¸ 1 â˜…â˜…â˜…
# ì„±ê³µì ìœ¼ë¡œ í›ˆë ¨ëœ ì²« ë²ˆì§¸ ëª¨ë¸ì˜ ê²½ë¡œë¥¼ ì •í™•íˆ ì§€ì •í•©ë‹ˆë‹¤.
YOLO_MODEL_PATH = os.path.join(PROJECT_ROOT, 'models', 'pitcher_detector', 'runs', 'detect', 'train', 'weights', 'best.pt')

# â˜…â˜…â˜… ìˆ˜ì • í¬ì¸íŠ¸ 2 â˜…â˜…â˜…
# ë¶„ì„í•˜ê³  ì‹¶ì€ ì˜¤íƒ€ë‹ˆ ì˜ìƒ íŒŒì¼ë“¤ì˜ ê²½ë¡œë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì§€ì •í•©ë‹ˆë‹¤.
# ohtani_videos í´ë”ì—ì„œ ì—¬ëŸ¬ ì˜ìƒì„ ì„ íƒí•˜ì—¬ ë¶„ì„í•©ë‹ˆë‹¤.
VIDEO_PATHS = [
    os.path.join(PROJECT_ROOT, 'data', 'raw', 'videos', 'ohtani_videos', '2018', '2018-04-01_529450_atbat_13_pitch_1_ST_Sweeper_none.mp4'),
    os.path.join(PROJECT_ROOT, 'data', 'raw', 'videos', 'ohtani_videos', '2018', '2018-04-01_529450_atbat_13_pitch_2_ST_Sweeper_none.mp4'),
    os.path.join(PROJECT_ROOT, 'data', 'raw', 'videos', 'ohtani_videos', '2018', '2018-04-01_529450_atbat_13_pitch_3_ST_Sweeper_strikeout.mp4'),
    os.path.join(PROJECT_ROOT, 'data', 'raw', 'videos', 'ohtani_videos', '2018', '2018-04-01_529450_atbat_14_pitch_1_FF_4-Seam_Fastball_none.mp4'),
    os.path.join(PROJECT_ROOT, 'data', 'raw', 'videos', 'ohtani_videos', '2018', '2018-04-01_529450_atbat_14_pitch_2_FF_4-Seam_Fastball_single.mp4')
]

# ë¶„ì„ ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
OUTPUT_DIR = os.path.join(PROJECT_ROOT, 'results', 'analyzed_videos')

# -------------------------------------------

# --- í•„ìš”í•œ ë„êµ¬ë“¤ ì´ˆê¸°í™” ---
try:
    yolo_model = YOLO(YOLO_MODEL_PATH)
except Exception as e:
    print(f"ì˜¤ë¥˜: YOLO ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”: {YOLO_MODEL_PATH}")
    print(f"ìƒì„¸ ì˜¤ë¥˜: {e}")
    exit()

# MediaPipe ëŒ€ì‹  ê°„ë‹¨í•œ ê°ì²´ íƒì§€ ê¸°ë°˜ ë¶„ì„ìœ¼ë¡œ ë³€ê²½

import os

# ë¶„ì„ ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
if not os.path.exists(OUTPUT_DIR):
    os.makedirs(OUTPUT_DIR)
    print(f"ğŸ“ ë¶„ì„ ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±: {OUTPUT_DIR}")

def analyze_single_video(video_path, yolo_model, output_dir):
    """ë‹¨ì¼ ì˜ìƒì„ ë¶„ì„í•˜ì—¬ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    print(f"\nğŸ¬ ë¶„ì„ ì‹œì‘: {video_path}")

    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"âŒ ì˜¤ë¥˜: ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")
        return None

    # ë¹„ë””ì˜¤ ì €ì¥ ì„¤ì •
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

    # ì¶œë ¥ ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ ì„¤ì •
    video_name = os.path.basename(video_path)
    output_path = os.path.join(output_dir, video_name.replace('.mp4', '_analyzed.mp4'))
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

    print(f"ğŸ“¹ ì¶œë ¥ íŒŒì¼: {output_path}")
    print(f"ğŸ“Š ë¹„ë””ì˜¤ ì •ë³´: {fps}fps, {width}x{height}")

    # í”„ë ˆì„ ì¹´ìš´í„° ë° íƒì§€ í†µê³„
    frame_count = 0
    detection_count = 0

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        frame_count += 1

        # YOLOë¡œ íˆ¬ìˆ˜ íƒì§€
        results = yolo_model(frame, verbose=False)

        if results and results[0].boxes:
            # ëª¨ë“  íƒì§€ëœ ê°ì²´ì— ëŒ€í•´ ì²˜ë¦¬
            for box in results[0].boxes:
                if box.conf > 0.5:  # ì‹ ë¢°ë„ 50% ì´ìƒ
                    detection_count += 1
                    xyxy = box.xyxy[0].cpu().numpy().astype(int)
                    x1, y1, x2, y2 = xyxy

                    # íƒì§€ëœ ì˜ì—­ì— ì‚¬ê°í˜• ê·¸ë¦¬ê¸°
                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)

                    # ì‹ ë¢°ë„ í‘œì‹œ
                    confidence = box.conf.item() * 100
                    cv2.putText(frame, f"Pitcher: {confidence:.1f}%", (x1, y1-10),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

        # í”„ë ˆì„ ì •ë³´ í‘œì‹œ
        cv2.putText(frame, f"Frame: {frame_count}", (10, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)

        # ì²˜ë¦¬ëœ í”„ë ˆì„ì„ ì¶œë ¥ ë¹„ë””ì˜¤ì— ì €ì¥
        out.write(frame)

        # ì§„í–‰ ìƒí™© ì¶œë ¥ (50í”„ë ˆì„ë§ˆë‹¤)
        if frame_count % 50 == 0:
            print(f"â³ ì²˜ë¦¬ ì¤‘: {frame_count} í”„ë ˆì„ ì™„ë£Œ, íƒì§€: {detection_count}")

    cap.release()
    out.release()

    detection_rate = (detection_count / frame_count) * 100 if frame_count > 0 else 0

    result = {
        'video_path': video_path,
        'output_path': output_path,
        'total_frames': frame_count,
        'detections': detection_count,
        'detection_rate': detection_rate
    }

    print(f"âœ… ë¶„ì„ ì™„ë£Œ: {os.path.basename(video_path)}")
    print(f"   ğŸ“Š ì´ í”„ë ˆì„: {frame_count}")
    print(f"   ğŸ¯ íˆ¬ìˆ˜ íƒì§€: {detection_count}")
    print(f"   ğŸ“ˆ íƒì§€ìœ¨: {detection_rate:.1f}%")

    return result

# --- ì—¬ëŸ¬ ì˜ìƒ ë°°ì¹˜ ë¶„ì„ ì‹œì‘ ---
print(f"\nğŸš€ ì´ {len(VIDEO_PATHS)}ê°œì˜ ì˜ìƒ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤!")
print("=" * 60)

all_results = []
successful_analyses = 0

for i, video_path in enumerate(VIDEO_PATHS, 1):
    print(f"\n[ {i}/{len(VIDEO_PATHS)} ] ë²ˆì§¸ ì˜ìƒ ì²˜ë¦¬ ì¤‘...")
    print("-" * 50)

    # ê° ì˜ìƒ ë¶„ì„
    result = analyze_single_video(video_path, yolo_model, OUTPUT_DIR)

    if result:
        all_results.append(result)
        successful_analyses += 1
    else:
        print(f"âŒ {video_path} ë¶„ì„ ì‹¤íŒ¨")

# --- ìµœì¢… ê²°ê³¼ ìš”ì•½ ---
print("\n" + "=" * 60)
print("ğŸ‰ ëª¨ë“  ì˜ìƒ ë¶„ì„ ì™„ë£Œ!")
print("=" * 60)
print(f"ğŸ“Š ë¶„ì„í•œ ì˜ìƒ ìˆ˜: {len(VIDEO_PATHS)}ê°œ")
print(f"âœ… ì„±ê³µí•œ ë¶„ì„: {successful_analyses}ê°œ")
print(f"âŒ ì‹¤íŒ¨í•œ ë¶„ì„: {len(VIDEO_PATHS) - successful_analyses}ê°œ")

if all_results:
    total_frames = sum(r['total_frames'] for r in all_results)
    total_detections = sum(r['detections'] for r in all_results)
    avg_detection_rate = sum(r['detection_rate'] for r in all_results) / len(all_results)

    print("\nğŸ“ˆ ì „ì²´ í†µê³„:")
    print(f"   ì´ í”„ë ˆì„ ìˆ˜: {total_frames}")
    print(f"   ì´ íƒì§€ ìˆ˜: {total_detections}")
    print(f"   í‰ê·  íƒì§€ìœ¨: {avg_detection_rate:.1f}%")

    print("\nğŸ“ ìƒì„±ëœ ë¶„ì„ ì˜ìƒë“¤:")
    for result in all_results:
        video_name = os.path.basename(result['output_path'])
        print(f"   âœ… {video_name} (íƒì§€ìœ¨: {result['detection_rate']:.1f}%)")

print(f"\nğŸ’¾ ëª¨ë“  ê²°ê³¼ëŠ” '{OUTPUT_DIR}' í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")