import cv2
import numpy as np
import pandas as pd
from ultralytics import YOLO
import os

def calculate_angle(a, b, c):
    """ì„¸ ì  a, b, cê°€ ì£¼ì–´ì¡Œì„ ë•Œ ì  b(íŒ”ê¿ˆì¹˜)ì—ì„œì˜ ê°ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
    # tensorë¥¼ numpyë¡œ ë³€í™˜ (GPU tensorì¸ ê²½ìš°)
    if hasattr(a, 'cpu'):
        a = a.cpu().numpy()
    if hasattr(b, 'cpu'):
        b = b.cpu().numpy()
    if hasattr(c, 'cpu'):
        c = c.cpu().numpy()

    # numpy arrayë¡œ ë³€í™˜
    a = np.asarray(a, dtype=np.float32) # ì–´ê¹¨
    b = np.asarray(b, dtype=np.float32) # íŒ”ê¿ˆì¹˜
    c = np.asarray(c, dtype=np.float32) # ì†ëª©

    # ë²¡í„° ê³„ì‚°
    ba = a - b  # ì–´ê¹¨ì—ì„œ íŒ”ê¿ˆì¹˜ë¡œì˜ ë²¡í„°
    bc = c - b  # ì†ëª©ì—ì„œ íŒ”ê¿ˆì¹˜ë¡œì˜ ë²¡í„°

    # ì½”ì‚¬ì¸ ë²•ì¹™ì„ ì‚¬ìš©í•œ ê°ë„ ê³„ì‚°
    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))
    cosine_angle = np.clip(cosine_angle, -1, 1)  # ë²”ìœ„ ì œí•œ
    angle = np.arccos(cosine_angle) * 180.0 / np.pi

    return angle

# --- 1. ì‚¬ìš©í•  ëª¨ë¸ ë° ì˜ìƒ ê²½ë¡œ ì„¤ì • ---

# ìŠ¤í¬ë¦½íŠ¸ì˜ ì ˆëŒ€ ê²½ë¡œë¥¼ ê¸°ì¤€ìœ¼ë¡œ í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ê³„ì‚°
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(os.path.dirname(SCRIPT_DIR))

# â˜…â˜…â˜… ìˆ˜ì • í¬ì¸íŠ¸ 1 â˜…â˜…â˜…
# ì„±ê³µì ìœ¼ë¡œ í›ˆë ¨ëœ ì²« ë²ˆì§¸ ëª¨ë¸ì˜ ê²½ë¡œë¥¼ ì •í™•íˆ ì§€ì •í•©ë‹ˆë‹¤.
YOLO_MODEL_PATH = os.path.join(PROJECT_ROOT, 'models', 'pitcher_detector', 'runs', 'detect', 'train', 'weights', 'best.pt')

# â˜…â˜…â˜… ìˆ˜ì • í¬ì¸íŠ¸ 2 â˜…â˜…â˜…
# ë¶„ì„í•˜ê³  ì‹¶ì€ ì˜¤íƒ€ë‹ˆ ì˜ìƒ íŒŒì¼ë“¤ì˜ ê²½ë¡œë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì§€ì •í•©ë‹ˆë‹¤.
# ohtani_videos í´ë”ì—ì„œ ì—¬ëŸ¬ ì˜ìƒì„ ì„ íƒí•˜ì—¬ ë¶„ì„í•©ë‹ˆë‹¤.
VIDEO_PATHS = [
    os.path.join(PROJECT_ROOT, 'data', 'raw', 'videos', 'ohtani_videos', '2018', '2018-04-01_529450_atbat_13_pitch_1_ST_Sweeper_none.mp4'),
    os.path.join(PROJECT_ROOT, 'data', 'raw', 'videos', 'ohtani_videos', '2018', '2018-04-01_529450_atbat_13_pitch_2_ST_Sweeper_none.mp4'),
    os.path.join(PROJECT_ROOT, 'data', 'raw', 'videos', 'ohtani_videos', '2018', '2018-04-01_529450_atbat_13_pitch_3_ST_Sweeper_strikeout.mp4'),
    os.path.join(PROJECT_ROOT, 'data', 'raw', 'videos', 'ohtani_videos', '2018', '2018-04-01_529450_atbat_14_pitch_1_FF_4-Seam_Fastball_none.mp4'),
    os.path.join(PROJECT_ROOT, 'data', 'raw', 'videos', 'ohtani_videos', '2018', '2018-04-01_529450_atbat_14_pitch_2_FF_4-Seam_Fastball_single.mp4')
]

# ë¶„ì„ ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
OUTPUT_DIR = os.path.join(PROJECT_ROOT, 'results', 'analyzed_videos')

# -------------------------------------------

# --- í•„ìš”í•œ ë„êµ¬ë“¤ ì´ˆê¸°í™” ---
try:
    pitcher_detector = YOLO(YOLO_MODEL_PATH)
    pose_estimator = YOLO('yolov8n-pose.pt')
except Exception as e:
    print(f"ì˜¤ë¥˜: YOLO ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”: {YOLO_MODEL_PATH}")
    print(f"ìƒì„¸ ì˜¤ë¥˜: {e}")
    exit()

# MediaPipe ëŒ€ì‹  ê°„ë‹¨í•œ ê°ì²´ íƒì§€ ê¸°ë°˜ ë¶„ì„ìœ¼ë¡œ ë³€ê²½

# ë¶„ì„ ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
if not os.path.exists(OUTPUT_DIR):
    os.makedirs(OUTPUT_DIR)
    print(f"ğŸ“ ë¶„ì„ ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±: {OUTPUT_DIR}")

def analyze_single_video(video_path, pitcher_detector, pose_estimator, output_dir):
    """ë‹¨ì¼ ì˜ìƒì„ ë¶„ì„í•˜ì—¬ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    print(f"\nğŸ¬ ë¶„ì„ ì‹œì‘: {video_path}")

    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"âŒ ì˜¤ë¥˜: ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")
        return None

    # ë¹„ë””ì˜¤ ì €ì¥ ì„¤ì •
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

    # ì¶œë ¥ ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ ì„¤ì •
    video_name = os.path.basename(video_path)
    output_path = os.path.join(output_dir, video_name.replace('.mp4', '_analyzed.mp4'))
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

    print(f"ğŸ“¹ ì¶œë ¥ íŒŒì¼: {output_path}")

    # --- â˜… 1. í‚¤(Key) ì¶”ì¶œ ë° ë¶„ì„ ë³€ìˆ˜ ì´ˆê¸°í™” â˜… ---

    # íŒŒì¼ëª…ì—ì„œ í‚¤(Key) íŒŒì‹± (ì˜ˆ: 2018-04-01_529450_atbat_13_pitch_1_ST...)
    try:
        parts = os.path.basename(video_path).split('_')
        game_pk = int(parts[1])
        at_bat_number = int(parts[3])
        pitch_number = int(parts[5])
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: íŒŒì¼ëª…ì—ì„œ í‚¤ë¥¼ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {os.path.basename(video_path)} -> {e}")
        return None # ì´ ë¹„ë””ì˜¤ ë¶„ì„ ì¤‘ë‹¨

    frame_count = 0
    detection_count = 0

    # ë¦´ë¦¬ìŠ¤ í¬ì¸íŠ¸ ì¶”ì ìš© ë³€ìˆ˜
    prev_wrist_pos = None
    max_wrist_velocity = -1
    angle_at_release = -1
    frame_at_release = -1

    analyzed_angles = [] # í”„ë ˆì„ë³„ ê°ë„ ì €ì¥ (í‰ê·  ê³„ì‚°ìš©)

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        frame_count += 1

        output_frame = frame.copy()

        # --- 1ë‹¨ê³„: íˆ¬ìˆ˜ íƒì§€ ---

        detect_results = pitcher_detector(frame, verbose=False)

        if detect_results and detect_results[0].boxes:
            box = detect_results[0].boxes[0]

            if box.conf > 0.5:
                detection_count += 1 # (ê¸°ì¡´ ì½”ë“œì—ì„œ ì´ë™)
                xyxy = box.xyxy[0].cpu().numpy().astype(int)
                x1, y1, x2, y2 = xyxy
                cv2.rectangle(output_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)

                # --- 2ë‹¨ê³„: ìì„¸ ì¶”ì • (Crop) ---

                pad = 20
                crop_x1 = max(0, x1 - pad); crop_y1 = max(0, y1 - pad)
                crop_x2 = min(frame.shape[1], x2 + pad); crop_y2 = min(frame.shape[0], y2 + pad)
                pitcher_crop = frame[crop_y1:crop_y2, crop_x1:crop_x2]

                if pitcher_crop.size == 0: continue

                pose_results = pose_estimator(pitcher_crop, verbose=False)
                annotated_crop = pose_results[0].plot() # ë¼ˆëŒ€ ê·¸ë¦¬ê¸°

                try:
                    if pose_results[0].keypoints and pose_results[0].keypoints.data.shape[1] == 17:
                        kpts = pose_results[0].keypoints.data[0] # (17, 3)

                        right_shoulder = kpts[6]
                        right_elbow = kpts[8]
                        right_wrist = kpts[10]

                        # ì‹ ë¢°ë„ ì„ê³„ê°’ ì„¤ì •
                        confidence_threshold = 0.3  # í‚¤í¬ì¸íŠ¸ ê²€ì¶œ ì„ê³„ê°’

                        # í‚¤í¬ì¸íŠ¸ê°€ ê²€ì¶œë˜ì—ˆëŠ”ì§€ í™•ì¸
                        keypoints_detected = (right_shoulder[2] > confidence_threshold and
                                            right_elbow[2] > confidence_threshold and
                                            right_wrist[2] > confidence_threshold)

                        if keypoints_detected:
                            # (A) ê°ë„ ê³„ì‚°
                            try:
                                angle = calculate_angle(right_shoulder[:2], right_elbow[:2], right_wrist[:2])
                                analyzed_angles.append(angle) # í‰ê·  ê³„ì‚°ìš© ì €ì¥

                                elbow_pos_crop = (int(right_elbow[0]), int(right_elbow[1]))
                                cv2.putText(annotated_crop, f"{angle:.1f}", (elbow_pos_crop[0] + 5, elbow_pos_crop[1]),
                                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

                            except Exception as e:
                                print(f"   [í”„ë ˆì„ {frame_count}] ê°ë„ ê³„ì‚° ì—ëŸ¬: {e}")
                                continue

                            # (B) ë¦´ë¦¬ìŠ¤ í¬ì¸íŠ¸(ìµœëŒ€ ì†ëª© ì†ë„) ê³„ì‚°
                            # tensorë¥¼ numpyë¡œ ë³€í™˜
                            if hasattr(right_wrist[:2], 'cpu'):
                                current_wrist_pos = right_wrist[:2].cpu().numpy()
                            else:
                                current_wrist_pos = np.asarray(right_wrist[:2])

                            # ë¦´ë¦¬ìŠ¤ í¬ì¸íŠ¸ ì¶”ì ì„ ìœ„í•œ ì´ˆê¸°í™”
                            if prev_wrist_pos is None:
                                prev_wrist_pos = current_wrist_pos
                                continue

                            # ìœ í´ë¦¬ë“œ ê±°ë¦¬ë¡œ ì†ë„ ê·¼ì‚¬ (í”½ì…€ ë‹¨ìœ„)
                            velocity = np.linalg.norm(current_wrist_pos - prev_wrist_pos)

                            # ìµœëŒ€ ì†ë„ ì—…ë°ì´íŠ¸ ë° ë¦´ë¦¬ìŠ¤ í¬ì¸íŠ¸ ê°ì§€
                            if velocity > max_wrist_velocity:
                                max_wrist_velocity = velocity
                                angle_at_release = angle
                                frame_at_release = frame_count

                            prev_wrist_pos = current_wrist_pos

                    # ë¼ˆëŒ€ì™€ ê°ë„ê°€ ê·¸ë ¤ì§„ cropì„ ì›ë³¸ í”„ë ˆì„ì— ë‹¤ì‹œ ë¶™ì—¬ë„£ê¸°
                    output_frame[crop_y1:crop_y2, crop_x1:crop_x2] = annotated_crop

                except Exception as e:
                    pass

        # (ì‹œê°í™”) ë¦´ë¦¬ìŠ¤ í”„ë ˆì„ í‘œì‹œ
        if frame_count == frame_at_release:
            cv2.putText(output_frame, "RELEASE!", (50, 80), cv2.FONT_HERSHEY_TRIPLEX, 1.5, (0, 0, 255), 2)

        cv2.putText(output_frame, f"Frame: {frame_count}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
        out.write(output_frame)

    # --- â˜… 2. ë£¨í”„ ì¢…ë£Œ í›„ ê²°ê³¼ ë°˜í™˜ â˜… ---

    cap.release()
    out.release()

    avg_angle = np.mean(analyzed_angles) if analyzed_angles else -1

    # ìµœì¢… ë¶„ì„ ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜
    result_data = {
        'game_pk': game_pk,
        'at_bat_number': at_bat_number,
        'pitch_number': pitch_number,
        'calculated_release_angle': angle_at_release,
        'calculated_avg_angle': avg_angle,
        'release_frame': frame_at_release,
        'max_wrist_velocity': max_wrist_velocity,
        'output_video_path': output_path,
        'detection_rate': (detection_count / frame_count) * 100 if frame_count > 0 else 0
    }

    print(f"âœ… ë¶„ì„ ì™„ë£Œ: {os.path.basename(video_path)}")
    print(f"   ğŸ”‘ Keys: {game_pk}, {at_bat_number}, {pitch_number}")
    print(f"   ğŸš€ ë¦´ë¦¬ìŠ¤ ê°ë„: {angle_at_release:.2f} (at frame {frame_at_release})")
    print(f"   ğŸ“Š í‰ê·  ê°ë„: {avg_angle:.2f}")

    return result_data # ê¸°ì¡´ result ë”•ì…”ë„ˆë¦¬ ëŒ€ì‹  ì´ ë”•ì…”ë„ˆë¦¬ë¥¼ ë°˜í™˜

# --- ì—¬ëŸ¬ ì˜ìƒ ë°°ì¹˜ ë¶„ì„ ì‹œì‘ ---
print(f"\nğŸš€ ì´ {len(VIDEO_PATHS)}ê°œì˜ ì˜ìƒ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤!")
print("=" * 60)

all_results = []
successful_analyses = 0

for i, video_path in enumerate(VIDEO_PATHS, 1):
    print(f"\n[ {i}/{len(VIDEO_PATHS)} ] ë²ˆì§¸ ì˜ìƒ ì²˜ë¦¬ ì¤‘...")
    print("-" * 50)

    # ê° ì˜ìƒ ë¶„ì„
    result = analyze_single_video(video_path, pitcher_detector, pose_estimator, OUTPUT_DIR)

    if result:
        all_results.append(result)
        successful_analyses += 1
    else:
        print(f"âŒ {video_path} ë¶„ì„ ì‹¤íŒ¨")

# --- ìµœì¢… ê²°ê³¼ ìš”ì•½ ë° CSV ì €ì¥ ---

print("\n" + "=" * 60)
print("ğŸ‰ ëª¨ë“  ì˜ìƒ ë¶„ì„ ì™„ë£Œ!")
print("=" * 60)

successful_analyses = len(all_results)
print(f"ğŸ“Š ë¶„ì„í•œ ì˜ìƒ ìˆ˜: {len(VIDEO_PATHS)}ê°œ")
print(f"âœ… ì„±ê³µí•œ ë¶„ì„: {successful_analyses}ê°œ")
print(f"âŒ ì‹¤íŒ¨í•œ ë¶„ì„: {len(VIDEO_PATHS) - successful_analyses}ê°œ")

if all_results:
    # ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
    results_df = pd.DataFrame(all_results)

    # CSV íŒŒì¼ë¡œ ì €ì¥
    csv_output_path = os.path.join(PROJECT_ROOT, 'results', 'video_analysis_results.csv')
    results_df.to_csv(csv_output_path, index=False, encoding='utf-8-sig')

    print("\nğŸ“ˆ ì „ì²´ í†µê³„:")
    print(f"   í‰ê·  ë¦´ë¦¬ìŠ¤ ê°ë„: {results_df['calculated_release_angle'].mean():.2f}")
    print(f"   í‰ê·  íƒì§€ìœ¨: {results_df['detection_rate'].mean():.1f}%")

    print(f"\nğŸ’¾ â˜…â˜…â˜… ë¶„ì„ ê²°ê³¼ê°€ CSV íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤! â˜…â˜…â˜…")
    print(f"   {csv_output_path}")
else:
    print("\në¶„ì„ì— ì„±ê³µí•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")