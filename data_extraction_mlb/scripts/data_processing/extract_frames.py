import cv2
import os
import glob
import numpy as np

video_folder = '../data/raw/videos/ohtani_videos/**/*.mp4' # ëª¨ë“  í•˜ìœ„ í´ë”ì˜ mp4 íŒŒì¼ì„ ëŒ€ìƒìœ¼ë¡œ í•¨
output_folder = '../data/processed/dataset/images'
frame_interval = 10 # 10í”„ë ˆì„ë§ˆë‹¤ 1ì¥ì”© ì €ì¥ (ìˆ«ìë¥¼ ì¤„ì´ë©´ ë” ë§ì€ ì´ë¯¸ì§€ ì¶”ì¶œ)

# ë¸”ëŸ¬ì²˜ë¦¬ ì„¤ì •
BLUR_FACES = True  # ì–¼êµ´ ë¸”ëŸ¬ì²˜ë¦¬ í™œì„±í™”/ë¹„í™œì„±í™”
BLUR_STRENGTH = 15  # ë¸”ëŸ¬ ê°•ë„ (í™€ìˆ˜ì—¬ì•¼ í•¨)

# ì–¼êµ´ ê²€ì¶œì„ ìœ„í•œ Haar Cascade ë¶„ë¥˜ê¸° ë¡œë“œ
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')

def blur_faces(frame):
    """
    í”„ë ˆì„ì—ì„œ ì–¼êµ´ì„ ê²€ì¶œí•˜ì—¬ ë¸”ëŸ¬ì²˜ë¦¬í•©ë‹ˆë‹¤.
    ì•¼êµ¬ ì˜ìƒì—ì„œëŠ” ì–¼êµ´ì´ ì‘ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì—¬ëŸ¬ ìŠ¤ì¼€ì¼ë¡œ ê²€ì¶œí•©ë‹ˆë‹¤.
    """
    if not BLUR_FACES:
        return frame

    # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜ (ì–¼êµ´ ê²€ì¶œìš©)
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

    # ì–¼êµ´ ê²€ì¶œ (ì—¬ëŸ¬ ìŠ¤ì¼€ì¼ë¡œ ê²€ì¶œí•˜ì—¬ ì‘ì€ ì–¼êµ´ë„ ì°¾ê¸°)
    faces = face_cascade.detectMultiScale(
        gray,
        scaleFactor=1.1,
        minNeighbors=3,
        minSize=(20, 20),  # ì•¼êµ¬ ì˜ìƒì—ì„œëŠ” ì–¼êµ´ì´ ì‘ì„ ìˆ˜ ìˆìŒ
        maxSize=(200, 200)  # ë„ˆë¬´ í° ì˜ì—­ì€ ì œì™¸
    )

    # ê° ì–¼êµ´ì— ë¸”ëŸ¬ ì ìš©
    for (x, y, w, h) in faces:
        # ì–¼êµ´ ì˜ì—­ ì¶”ì¶œ
        face_roi = frame[y:y+h, x:x+w]

        # ë¸”ëŸ¬ ì ìš©
        blurred_face = cv2.GaussianBlur(face_roi, (BLUR_STRENGTH, BLUR_STRENGTH), 0)

        # ë¸”ëŸ¬ëœ ì–¼êµ´ì„ ì›ë³¸ í”„ë ˆì„ì— ì ìš©
        frame[y:y+h, x:x+w] = blurred_face

    return frame

if not os.path.exists(output_folder):
    os.makedirs(output_folder)

video_files = glob.glob(video_folder, recursive=True)
print(f"ì´ {len(video_files)}ê°œì˜ ë¹„ë””ì˜¤ íŒŒì¼ì—ì„œ ì´ë¯¸ì§€ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.")

if BLUR_FACES:
    print("ğŸ” ì–¼êµ´ ë¸”ëŸ¬ì²˜ë¦¬ê°€ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"   ë¸”ëŸ¬ ê°•ë„: {BLUR_STRENGTH}")
else:
    print("â„¹ï¸  ì–¼êµ´ ë¸”ëŸ¬ì²˜ë¦¬ê°€ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

total_processed = 0
for i, video_path in enumerate(video_files):
    print(f"\nğŸ“¹ [{i+1}/{len(video_files)}] '{os.path.basename(video_path)}' ì²˜ë¦¬ ì¤‘...")

    cap = cv2.VideoCapture(video_path)
    frame_count = 0
    video_name = os.path.basename(video_path).replace('.mp4', '')
    video_processed = 0

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        if frame_count % frame_interval == 0:
            # ë¸”ëŸ¬ì²˜ë¦¬ ì ìš© (í™œì„±í™”ëœ ê²½ìš°)
            processed_frame = blur_faces(frame.copy())

            image_name = f"{video_name}_frame_{frame_count}.jpg"
            cv2.imwrite(os.path.join(output_folder, image_name), processed_frame)
            video_processed += 1

        frame_count += 1

    cap.release()
    total_processed += video_processed
    print(f"   âœ… {video_processed}ê°œ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ")

print("
ğŸ‰ ì „ì²´ ì²˜ë¦¬ ì™„ë£Œ!")
print(f"   ì´ ì €ì¥ëœ ì´ë¯¸ì§€: {total_processed}ê°œ")
print(f"   ì¶œë ¥ í´ë”: {os.path.abspath(output_folder)}")